{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = \"\"\n",
    "sampling_rate=100\n",
    "\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id', nrows=1000)\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "# Train\n",
    "X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "# Test\n",
    "X_test = X[np.where(Y.strat_fold == test_fold)]\n",
    "y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecg_id\n",
       "1         [NORM]\n",
       "2         [NORM]\n",
       "3         [NORM]\n",
       "4         [NORM]\n",
       "5         [NORM]\n",
       "6         [NORM]\n",
       "7         [NORM]\n",
       "8           [MI]\n",
       "10        [NORM]\n",
       "11        [NORM]\n",
       "12        [NORM]\n",
       "13        [NORM]\n",
       "14        [NORM]\n",
       "15        [NORM]\n",
       "16        [NORM]\n",
       "17            []\n",
       "18            []\n",
       "19        [NORM]\n",
       "20            []\n",
       "21        [NORM]\n",
       "22        [STTC]\n",
       "23            []\n",
       "24        [NORM]\n",
       "25        [NORM]\n",
       "26        [STTC]\n",
       "27        [NORM]\n",
       "28        [STTC]\n",
       "29        [NORM]\n",
       "30         [HYP]\n",
       "31        [NORM]\n",
       "32          [CD]\n",
       "33        [NORM]\n",
       "34            []\n",
       "35        [NORM]\n",
       "36        [NORM]\n",
       "37        [NORM]\n",
       "39    [MI, STTC]\n",
       "41          [CD]\n",
       "42        [NORM]\n",
       "43        [NORM]\n",
       "Name: diagnostic_superclass, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform y_train\n",
    "y_train_encoded = mlb.fit_transform(y_train)\n",
    "\n",
    "# Transform y_test\n",
    "y_test_encoded = mlb.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reshape X_train and X_test to 2D arrays\n",
    "X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform X_train\n",
    "X_train_normalized = scaler.fit_transform(X_train_2d)\n",
    "\n",
    "# Transform X_test using the scaler fitted on the training data\n",
    "X_test_normalized = scaler.transform(X_test_2d)\n",
    "\n",
    "# Reshape the normalized data back to 3D arrays\n",
    "X_train_normalized = X_train_normalized.reshape(X_train.shape)\n",
    "X_test_normalized = X_test_normalized.reshape(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.119, -0.055,  0.064, ..., -0.026, -0.039, -0.079],\n",
       "       [-0.116, -0.051,  0.065, ..., -0.031, -0.034, -0.074],\n",
       "       [-0.12 , -0.044,  0.076, ..., -0.028, -0.029, -0.069],\n",
       "       ...,\n",
       "       [ 0.069,  0.   , -0.069, ...,  0.024, -0.041, -0.058],\n",
       "       [ 0.086,  0.004, -0.081, ...,  0.242, -0.046, -0.098],\n",
       "       [ 0.022, -0.031, -0.054, ...,  0.143, -0.035, -0.12 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.58750481, -0.21148667,  0.33338439, ..., -0.11371942,\n",
       "        -0.11485571, -0.23213584],\n",
       "       [-0.57455839, -0.20551289,  0.33464201, ..., -0.12555121,\n",
       "        -0.10439688, -0.22328593],\n",
       "       [-0.57388145, -0.17260534,  0.37710371, ..., -0.11427138,\n",
       "        -0.08913142, -0.20902292],\n",
       "       ...,\n",
       "       [ 0.29920911,  0.04117644, -0.24856195, ...,  0.03977347,\n",
       "        -0.14466081, -0.14651976],\n",
       "       [ 0.33285364,  0.02528715, -0.30445359, ...,  0.66075497,\n",
       "        -0.19131544, -0.3107622 ],\n",
       "       [ 0.05570448, -0.1758299 , -0.21779973, ...,  0.33600234,\n",
       "        -0.17189612, -0.40157453]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape of training data\n",
    "```number of examples x (sampling frequency*10 seconds) x number of channels/leads```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871, 1000, 12), (871, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized.shape, y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-D to 2-D conversion\n",
    "``` (Research the best way to do it!)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_normalized = X_train_normalized.reshape(X_train_normalized.shape[0], -1)\n",
    "# X_test_normalized = X_test_normalized.reshape(X_test_normalized.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_normalized.shape[1],)), \n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(y_train_encoded.shape[1], activation='sigmoid')  # Sigmoid activation for multi-label classification\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "278/278 [==============================] - 6s 14ms/step - loss: 0.6403 - accuracy: 0.3665 - val_loss: 0.5757 - val_accuracy: 0.4192\n",
      "Epoch 2/10\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.4785 - accuracy: 0.5132 - val_loss: 0.5870 - val_accuracy: 0.3996\n",
      "Epoch 3/10\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.3933 - accuracy: 0.5831 - val_loss: 0.6198 - val_accuracy: 0.3988\n",
      "Epoch 4/10\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.3214 - accuracy: 0.6475 - val_loss: 0.6857 - val_accuracy: 0.4192\n",
      "Epoch 5/10\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.2688 - accuracy: 0.7021 - val_loss: 0.7424 - val_accuracy: 0.4067\n",
      "Epoch 6/10\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.2283 - accuracy: 0.7386 - val_loss: 0.8003 - val_accuracy: 0.4032\n",
      "Epoch 7/10\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.1941 - accuracy: 0.7677 - val_loss: 0.9482 - val_accuracy: 0.4085\n",
      "Epoch 8/10\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.1779 - accuracy: 0.7890 - val_loss: 0.9809 - val_accuracy: 0.3988\n",
      "Epoch 9/10\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.1559 - accuracy: 0.8078 - val_loss: 1.0565 - val_accuracy: 0.4210\n",
      "Epoch 10/10\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.1353 - accuracy: 0.8199 - val_loss: 1.1445 - val_accuracy: 0.4130\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_normalized, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test_normalized, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1445 - accuracy: 0.4130\n",
      "Test Loss: 1.1445200443267822\n",
      "Test Accuracy: 0.412966251373291\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "# Round predictions to convert probabilities to binary values\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_normalized, y_test_encoded)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Each Label: [0.33505155 0.12871287 0.2939759  0.61851852 0.29910714]\n",
      "Average F1 Score: 0.42637189103829454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score for each label\n",
    "f1_scores = f1_score(y_test_encoded, y_pred_binary, average=None)\n",
    "\n",
    "# Calculate average F1 score across all labels\n",
    "average_f1_score = f1_score(y_test_encoded, y_pred_binary, average='micro')\n",
    "\n",
    "# Print F1 score for each label and average F1 score\n",
    "print(\"F1 Score for Each Label:\", f1_scores)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
